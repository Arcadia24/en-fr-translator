{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utilisateur/createch/IA/A5/wite_me_a_poeme/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Some standard imports\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.onnx\n",
    "from new_transformer import Transformer\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedding(1210, 600)\n",
       "    (pos_encoding): SinusoidEncoding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x Block(\n",
       "        (qkv): Linear(in_features=600, out_features=1800, bias=False)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (fc_out): Linear(in_features=600, out_features=600, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (0): Linear(in_features=600, out_features=2400, bias=False)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2400, out_features=600, bias=False)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(1210, 600)\n",
       "    (pos_encoding): SinusoidEncoding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (qkv): Linear(in_features=600, out_features=1800, bias=False)\n",
       "        (mmha): MultiHeadAttention(\n",
       "          (fc_out): Linear(in_features=600, out_features=600, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (mha): MultiHeadAttention(\n",
       "          (fc_out): Linear(in_features=600, out_features=600, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ffwd): FeedForward(\n",
       "          (0): Linear(in_features=600, out_features=2400, bias=False)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=2400, out_features=600, bias=False)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (normraw): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (normenc): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((600,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=600, out_features=1210, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = Transformer(\n",
    "    vocab_size=1210,\n",
    "    n_head=6,\n",
    "    embed_size=600,\n",
    "    context_length=100,\n",
    "    dropout=0.1,\n",
    "    num_layers=6,\n",
    "    device=device,\n",
    ")\n",
    "model.load_state_dict(torch.load(\"saved_model_tokenizer_3.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]) tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True]]]]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]) tensor([[[[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]]]])\n",
      "torch.Size([1, 100]) torch.Size([1, 1, 1, 100]) torch.Size([1, 100]) torch.Size([1, 1, 100, 100])\n",
      "torch.int64 torch.bool torch.int64 torch.bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2270, -9.7406, -7.8299,  ..., -2.8887, -3.0761, -3.3137],\n",
       "         [-2.2272, -9.7407, -7.8299,  ..., -2.8872, -3.0742, -3.3164],\n",
       "         [-2.2256, -9.7385, -7.8286,  ..., -2.8864, -3.0726, -3.3164],\n",
       "         ...,\n",
       "         [-2.2209, -9.7404, -7.8287,  ..., -2.8924, -3.0778, -3.3111],\n",
       "         [-2.2215, -9.7414, -7.8283,  ..., -2.8932, -3.0797, -3.3067],\n",
       "         [-2.2239, -9.7431, -7.8289,  ..., -2.8939, -3.0803, -3.3043]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "src = torch.zeros((batch_size, 100),dtype= torch.int64)\n",
    "src_mask = torch.ones((batch_size, 1, 1, 100), dtype= torch.bool)\n",
    "tgt = torch.zeros((batch_size, 100),dtype= torch.int64)\n",
    "tgt_mask = torch.ones((batch_size, 1, 100, 100), dtype= torch.bool)\n",
    "print(src, src_mask, tgt, tgt_mask)\n",
    "\n",
    "print(src.shape, src_mask.shape, tgt.shape, tgt_mask.shape)\n",
    "print(src.dtype, src_mask.dtype, tgt.dtype, tgt_mask.dtype)\n",
    "\n",
    "torch_out = model(src, tgt, src_mask, tgt_mask)\n",
    "torch_out.shape\n",
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,               # model being run\n",
    "                  (src,tgt,src_mask,tgt_mask),                         # model input (or a tuple for multiple inputs)\n",
    "                  \"model_1.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=17,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['source', 'target', 'source_mask', 'target_mask'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'target' : {1: 'context_length'}, \n",
    "                                'target_mask' : {2: 'dim_mask',3: 'context_length'},\n",
    "                                'output' : {1: 'context_length'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"model_1.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-2.2269676 -9.740591  -7.829893  ... -2.8886979 -3.0761008 -3.3136947]\n",
      "  [-2.2272356 -9.740738  -7.8298564 ... -2.88724   -3.0742009 -3.3163526]\n",
      "  [-2.225567  -9.738461  -7.8286386 ... -2.8863773 -3.0725954 -3.3164423]\n",
      "  ...\n",
      "  [-2.2209232 -9.74035   -7.828696  ... -2.892378  -3.0777695 -3.3110888]\n",
      "  [-2.2214565 -9.741371  -7.82825   ... -2.8931556 -3.0797226 -3.3066583]\n",
      "  [-2.223932  -9.743134  -7.8289456 ... -2.8939233 -3.0802665 -3.3042738]]]\n",
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ort_session = ort.InferenceSession(\"model_1.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(src).astype('int64') ,\n",
    "              ort_session.get_inputs()[1].name: to_numpy(tgt).astype('int64'),\n",
    "              ort_session.get_inputs()[2].name: to_numpy(src_mask).astype('bool'),\n",
    "              ort_session.get_inputs()[3].name: to_numpy(tgt_mask).astype('bool')}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "print(ort_outs[0])\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/encoder/layers.0/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.0/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.1/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.1/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.2/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.2/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.3/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.3/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.4/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.4/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.5/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/encoder/layers.5/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.0/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.0/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.0/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.0/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.1/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.1/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.1/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.1/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.2/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.2/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.2/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.2/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.3/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.3/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.3/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.3/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.4/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.4/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.4/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.4/mha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.5/mmha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.5/mmha/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.5/mha/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/decoder/layers.5/mha/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "quantize_dynamic(\"model_1.onnx\", \"model_1_quantized.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]]) tensor([[[[True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True, True, True, True, True, True, True, True, True, True, True,\n",
      "           True]]]]) tensor([[ 471,  843,  137,  444, 1139,  729,  676,  504,  259,  658,  947,  420,\n",
      "          755,  156,  584,  448,  670,  952,  100,  570,  722, 1152,  702,  821,\n",
      "          131,  113, 1178,  346,  929,  224,  969,  684,  252,  481,  891,  315,\n",
      "          717,  560,  375,  750, 1006,  121,  220,   14,  761,  280,  969,  913,\n",
      "          501,  670,  527,  129,  223,  382,  831, 1123,  715, 1139,  661,  312,\n",
      "          505,  235,  533, 1172,  283,  781,  741,   58,  414, 1191,  950,  188,\n",
      "         1052, 1102, 1124,  865,  860,  732,  559,  557,  938,  197,   47,  442,\n",
      "          196, 1136, 1189,  873, 1039,   42,  368,  877,  170,  154,  843,   28,\n",
      "          548,  951,  587,  356]]) tensor([[[[True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          ...,\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True],\n",
      "          [True, True, True,  ..., True, True, True]]]])\n",
      "[[[ -2.2707264 -10.39834    -8.164363  ...  -2.7502358  -3.0317287\n",
      "    -2.566596 ]\n",
      "  [ -2.3503067 -10.018869   -8.134374  ...  -2.591075   -2.979504\n",
      "    -3.199729 ]\n",
      "  [ -2.0241587 -10.496499   -8.39696   ...  -2.3833466  -3.0723236\n",
      "    -3.2763104]\n",
      "  ...\n",
      "  [ -1.6735803 -10.189588   -8.2484045 ...  -2.259514   -3.3335934\n",
      "    -2.8416169]\n",
      "  [ -1.9594263  -9.966572   -7.706482  ...  -2.6558802  -3.2235851\n",
      "    -3.4799428]\n",
      "  [ -2.041201  -10.2062645  -8.093705  ...  -1.9207118  -3.2610347\n",
      "    -2.5360951]]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 120186 / 121000 (99.3%)\nMax absolute difference: 3.167286\nMax relative difference: 23548.799\n x: array([[[-2.226967, -9.740591, -7.829891, ..., -2.888696, -3.076103,\n         -3.313692],\n        [-2.227233, -9.740733, -7.829851, ..., -2.887239, -3.074201,...\n y: array([[[ -2.270726, -10.39834 ,  -8.164363, ...,  -2.750236,\n          -3.031729,  -2.566596],\n        [ -2.350307, -10.018869,  -8.134374, ...,  -2.591075,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(ort_outs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# compare ONNX Runtime and PyTorch results\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_allclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mort_outs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-03\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExported model has been tested with ONNXRuntime, and the result looks good!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/createch/IA/A5/wite_me_a_poeme/.venv/lib/python3.10/site-packages/numpy/testing/_private/utils.py:862\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf, strict)\u001b[0m\n\u001b[1;32m    858\u001b[0m         err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remarks)\n\u001b[1;32m    859\u001b[0m         msg \u001b[38;5;241m=\u001b[39m build_err_msg([ox, oy], err_msg,\n\u001b[1;32m    860\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    861\u001b[0m                             names\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m), precision\u001b[38;5;241m=\u001b[39mprecision)\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 120186 / 121000 (99.3%)\nMax absolute difference: 3.167286\nMax relative difference: 23548.799\n x: array([[[-2.226967, -9.740591, -7.829891, ..., -2.888696, -3.076103,\n         -3.313692],\n        [-2.227233, -9.740733, -7.829851, ..., -2.887239, -3.074201,...\n y: array([[[ -2.270726, -10.39834 ,  -8.164363, ...,  -2.750236,\n          -3.031729,  -2.566596],\n        [ -2.350307, -10.018869,  -8.134374, ...,  -2.591075,..."
     ]
    }
   ],
   "source": [
    "\n",
    "ort_session_2 = ort.InferenceSession(\"model_1_quantized.onnx\")\n",
    "tgt = torch.randint(0,1210,(batch_size, 100),dtype= torch.int64)\n",
    "tgt_mask = torch.ones((batch_size, 1, 100, 100), dtype= torch.bool)\n",
    "print(src, src_mask, tgt, tgt_mask)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs_2 = {ort_session_2.get_inputs()[0].name: to_numpy(src).astype('int64') ,\n",
    "              ort_session_2.get_inputs()[1].name: to_numpy(tgt).astype('int64'),\n",
    "              ort_session_2.get_inputs()[2].name: to_numpy(src_mask).astype('bool'),\n",
    "              ort_session_2.get_inputs()[3].name: to_numpy(tgt_mask).astype('bool')}\n",
    "ort_outs = ort_session_2.run(None, ort_inputs_2)\n",
    "print(ort_outs[0])\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
